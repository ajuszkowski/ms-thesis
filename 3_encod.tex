\chapter{Portability analysis as an SMT problem}
\label{ch:enc}

As it was discussed in Chapter~\ref{ch:intro}, a concurrent program may behave differently when compiled for different hardware architectures.
This may cause the portability bugs, the behaviour that is allowed under one architecture and forbidden under another. 
This Chapter provides the short introduction into the general model checking and reachability analysis problem, after which it describes of the concurrent software portability analysis stated as a \textit{bounded reachability} problem, which in turn can be reduced to an SMT problem~\cite{Porthos17b}.

%TODO: sound, complete...

\section{Model checking and reachability analysis}
\label{ch:enc:mc}

The \textit{model checking} is the problem of verifying the system (the \textit{model}) against a set of constraints (the \textit{specification})~\cite{dkw2008}.
As the state machine is the most widespread mathematical model of computation, most classical model checking algorithms explore the state space of a system in order to find states that violate the specification.

The general scheme of model checking is the following.
The analysing system is represented as a transition system, a directed graph with labelled nodes representing states of the system.
Each state corresponds to the unique subset of atomic propositions that characterise its behavioural properties.
Once the model has been constructed, it can be checked for compliance to the specification, a set of constraints.

Usually, the specification defines temporal constraints over the system properties.
For instance, the specification can assert that the property \textit{always} holds (the \textit{safety} property) or the property will \textit{eventually} hold (the \textit{liveness} property).
Commonly, the \textit{Linear Temporal Logic~(LTL)} or \textit{Computational Tree Logic~(CTL)} (along with their extensions) is used as a specification language due to the expressiveness and verifiability of their statements~\cite{clarke1999model}.

In the described scheme, the model checking problem is reducible to the reachability analysis, an iterative process of a systematic exhaustive search in the state space.
This approach is called \textit{Unbounded Model Checking~(UMC)}.
However, all model checking techniques are exposed to the \textit{state explosion problem} as the size of the state space grows exponentially with respect to the number of state variables used by the system (its size).
In case of modelling concurrent systems, this problem becomes much more serious due to the exponential number of possible interleavings of states.
Therefore, over past 30 years the research in model checking has been fighting the state explosion problem mostly by optimising search space, search strategy or basic data structures of existing algorithms~\cite{clarke2001progress}.

One of the first techniques that optimises the search space considerably is the symbolic model checking with \textit{Binary Decision Diagrams~(BDDs)}~\cite{burch1992symbolic}.
Instead of processing each state individually, in this approach the set of states is represented by the BDD, a data structure that allow to perform operations on large boolean formulas efficiently~\cite{clarke2012model}.
The BDD representation can be linear of size of variables it encodes if the ordering of variables is optimal, otherwise the size of BDD is exponential.
The problem of finding such an optimal ordering is known as NP-complete problem, which makes this approach inapplicable in some cases.

The other idea is to use satisfiability solvers for symbolic exploration of state space~\cite{clarke2001bounded}.
In this approach, the state space exploration consists of the sequence of queries to the SAT-solver, represented as boolean formulas that encode the constraints of the model and the finite path to a state in the corresponding transition system.
%This approach uses an iterative process of constructing queries to the SAT-solver as a boolean formula which encodes the constraints of the model and the finite path to a state in the corresponding transition system. 
%Due to the SAT-solver.
This technique is called \textit{Bounded Model Checking~(BMC)} as the search process is being repeated up to the user-defined bound $k$, which may result to \textit{incomplete analysis} in general case (not all the state space has been checked).
However, there exist numerous techniques for making BMC complete for finite-state systems~(e.g.,~\cite{shtrichman2000tuning}).

At present time, satisfiability solvers are behind the numerous verification and bounded model checking tools.
Although, as most modern programming languages are typed, the SAT-formula that encodes the constraints of a program must include non-boolean constraints encoded as boolean variables, which is ineffective, therefore most software analysis and verification tools use \textit{Satisfiability Modulo Theories~(SMT)} -solvers, that integrate first-order reasoning with the background theory reasoning~\cite{kroening2008decision}.
For example, the Integer theory includes operators `$+$', `$-$', `$\geqslant$' and others).
Most modern SMT-solvers support integer arithmetic, real arithmetic, fixed-size bit-vectors, arrays, and other theories.
The direction of the development of SMT-solvers is provided by the \texttt{SMT-LIB} standard~\cite{smt-lib}, which provides definition of the unified language for defining SMT-formulas, and description of most common underlying logics and theories.

In general, a BMC problem aims to examine the non-reachability of the "undesirable" states of a finite-state system.
Let $\vec{x} = (x_1, x_2, ..., x_n)$ be a vector of $n$ variables that uniquely distinguishes states of the system; let $\textit{Init}(\vec{x})$ be an \textit{initial-state predicate} that defines the set of initial states of the system; let $\textit{Trans}(\vec{x}, \pvec{x}')$ be a \textit{transition predicate} that signifies whether there the transition from state $\vec{x}$ to state $\pvec{x}'$ is valid; let $\textit{Bad}(\vec{x})$ be a \textit{bad-state predicate} that defines the set of undesirable states.
Then, the BMC problem, stated as the reachability of the undesirable state withing $k$ steps, is formulated as following:
$\texttt{SAT}( \textit{Init}(\vec{x_0}) \land \textit{Trans}(\vec{x}_0, \vec{x}_1) \land ... \land \textit{Trans}(\vec{x}_{k-1}, \vec{x}_k) \land \textit{Bad}(\vec{x}_k) )$.


\section{Portability analysis as a bounded reachability problem}
\label{ch:enc:bmc}

A portability analysis problem may be stated as a reachability problem, where the undesirable state is one reachable under the target~$\mathcal{M_T}$ memory model and unreachable under the source memory model~$\mathcal{M_S}$.
%However, unlikely a BMC problem, the portability analysis does not require to call the SMT solver repeatedly, since (imperative) programs may be converted as acyclic state graph (by reducing the loops, see Section~\ref{ch:impl:proc:x-transf}) and the $Trans$ predicate may be stated only for the final state of a program.
Consider the function $\textit{cons}_{\mathcal{M}}(P)$ which calculates the set of executions of the program $P$ that are consistent under the memory model $\mathcal{M}$.
The program $P$ is called portable from the source architecture (memory model) $\mathcal{M_S}$ to the target architecture $\mathcal{M_T}$ if all executions consistent under $\mathcal{M_T}$ are consistent under $\mathcal{M_S}$~\cite{Porthos17a}:

\begin{definition}[Portability]
Let $\mathcal{M_S}$, $\mathcal{M_T}$ be two weak memory models.
The program $P$ is portable from $\mathcal{M_S}$ to $\mathcal{M_T}$ if 
$\textit{cons}_{\mathcal{M_T}}(P) \subseteq \textit{cons}_{\mathcal{M_S}}(P)$
\end{definition}

Note that the definition of portability requirements against \textit{executions} is strong enough, as it implies the portability against \textit{states} (the \textit{state-portability})~\cite{Porthos17b}.
The result SMT-formula $\phi$ that encodes the portability problem should contain both encodings of control-flow $\phi_{CF}$ and data-flow $\phi_{DF}$ of the program, and assertions of both memory models: ${\phi \defeq \phi_{CF} \land \phi_{DF} \land \phi_{\mathcal{M_T}} \land \phi_{\lnot\mathcal{M_S}}}$.
If the formula is satisfiable, there exist a portability bug.
%The control-flow and data-flow encodings are standard for BMC~\cite{collavizza2006exploration}, they are described below. 
%However, encoding of memory models requires additional techniques due to recursive definitions of relations, that were proposed in~\cite{Porthos17a}.


\subsection{Encoding for the control-flow} %Encoding the control-flow constraints}
\label{ch:enc:bmc:cf}

The control-flow of a program can be represented by the \textit{control-flow graph}, a directed acyclic connected graph with a single source and one or multiple sink nodes.
Each control-flow edge contains the label that denotes the transition predicate called \textit{guard}.
The empty guard (a \textit{true} predicate) is denoted as `$\epsilon$'.
A guard represents a variable or a computational expression over local variables.
As a guard depends on the data-flow of the program, it is liable to the weak memory model relaxations.
The branching expressions that support more than two outgoing control-flow edges may be useful for describing non-deterministic transition systems, where the guards are not necessarily mutually exclusive.
However, as the C language supports only binary logic (\textit{if-then-else} branching), \porthos[2] builds only two possible outcomes of evaluating a computation (the \textit{primary} and \textit{alternative} transitions), see Section~\ref{ch:impl:model:xgraph} for details.

While working on \porthos[2], we have applied some modifications to the encoding scheme for the control-flow.
These changes were motivated by the need to process an arbitrary control-flow produced by conditional and unconditional jumps of the C language.
For that, we compile the \textit{Abstract Syntax Tree~(AST)} of the parsed C-code to the plain event-flow graph.
The new encoding is to be smaller than the old one used in \porthos{} since it does not produce new variables for each high-level statement of the input language.

For instance, \porthos[1] uses the encoding scheme where the control-flow of the sequential instruction $i_1 = i_2; i_3$ is encoded recursively as %a separate boolean variable
$\phi_{CF}(i_2;i_3) \defeq (cf_{i_1} \Leftrightarrow (cf_{i_2} \land cf_{i_3})) \land \phi_{CF}(i_2) \land \phi_{CF}(i_3)$,
and the control-flow of the branching instruction $i_1 = (c\,?\,i_2\!:\!i_3)$ was encoded recursively as
$\phi_{CF}(c\,?\,i_2\!:\!i_3) \defeq (\textit{cf}_{i_1} \Leftrightarrow (\textit{cf}_{i_2} \lor \textit{cf}_{i_3})) \land \phi_{CF}(i_2) \land \phi_{CF}(i_3)$.
%$\phi_{CF}(c\,?\,i_2\!:\!i_3)
%(here we used the notation of C-like ternary operator `\texttt{x?y:z}' for defining the conditional expression `$\texttt{if}\;x\;\texttt{then}\;y\;\texttt{else}\;z$').
In contrast, the new encoding scheme implemented in \porthos[2] firstly compiles the recursive high-level instructions into the linear low-level event-flow graph, which is then encoded into an SMT-formula.
A guard in the event-flow graph is a value of conditional variable on the branching event, which is encoded as a data-flow constraint (see Section~\ref{ch:enc:bmc:df}).
In general, the new encoding scheme follows the one proposed in~\cite[Chapter 5.1.2]{heljanko2008unfoldings} for encoding Petri-nets.


\begin{figure}%[b]
  \centering
  \begin{minipage}{\textwidth}
      \begin{subfigure}[b]{0.3\textwidth}
        \makebox[\textwidth]{
        \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.5cm,semithick]
            \node[c] (1) [] {$e_i$};
            \node[c] (2) [below of=1] {$e_{i+1}$};
            \path[->]
            (1) edge [] node {$\epsilon$} (2)
            ;
        \end{tikzpicture}
        }
        \caption{Sequence of events (seq)}
        \label{encode:cf:seq}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.35\textwidth}
        \makebox[\textwidth] {
        \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.5cm,semithick]
            \node[c]           (k)   [] {$e_k$};
            \node[c,draw=none] (iii) [below of=k] {$...$};
            \node[c,draw=none] (ii)  [left=0.2cm of iii] {};
            \node[c]           (i)   [left=0.2cm of ii] {$e_i$};
            \node[c,draw=none] (iv)  [right=0.2cm of iii] {};
            \node[c]           (v)   [right=0.2cm of iv] {$e_{i+j}$};
            \path[->]
            (k) edge [above] node {$g_{i,k}$} (i)
            (k) edge [] node {} (ii)
            (k) edge [] node {} (iii)
            (k) edge [] node {} (iv)
            (k) edge [above] node {$g_{i+j,k}$} (v)
            ;
        \end{tikzpicture}
        }
        \caption{Conditional branching (br)}
        \label{encode:cf:br}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.25\textwidth}
        \makebox[\textwidth]{
        \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.5cm,semithick]
            \node[c] (i) [] {$e_i$};
            \node[c,draw=none] (ii) [right=0.2cm of i] {};
            \node[c,draw=none] (iii) [right=0.2cm of ii] {$...$};
            \node[c,draw=none] (iv) [right=0.2cm of iii] {};
            \node[c] (v) [right=0.2cm of iv] {$e_{i+j}$};
            \node[c] (k) [below of=iii] {$e_k$};
            \path[->]
            (i) edge [above] node {$g_{i,k}$} (k)
            (ii) edge [above] node {} (k)
            (iii) edge [] node {} (k)
            (iv) edge [] node {} (k)
            (v) edge [] node {} (k) %sloped
            ;
        \end{tikzpicture}
        }
        \caption{Branch merging (mer)}
        \label{encode:cf:merge}
    \end{subfigure}
    %
    \caption{Possible mutual arrangements of events in an event-flow graph} %Linear and non-linear cases of a control-flow graph}
    \label{encode:cf}
\end{minipage}
\end{figure}

Let $\fx:\,\mathbb{E}\,\rightarrow\,\{0,1\}$ be the predicate that signifies the fact that the event has been e\textbf{x}ecuted (and, consequently, has changed the state of the system).
%Let $\fv:\,\mathbb{C}\,\rightarrow\,\mathbb{R}$ be the function that returns the value of the computation event (evaluates it) that will be computed once the event is executed (strictly speaking, it returns the \textit{set} of values determined by the \rf-relation; see Section~\ref{ch:wmm:model:relations} for details on relations).
%We distinguish the function ${\fv_g\;:\;\mathbb{C}_g\;\rightarrow\;\{0,1\}}$ that evaluates the guard computation event. In the result formula, all symbols $\fx(e_i)$ and $\fv(e_i)$ are encoded as boolean variables.
Consider the possible mutual arrangements of nodes in an event-flow graph presented in Figure~\ref{encode:cf}.
For these cases, we propose the encoding scheme that uniquely encodes each node of graph and at the same time allows to encode partially executed program:

\begin{align}
\phi_{CF_{seq}} \defeq \quad & \fx(e_{i+1}) \Rightarrow \fx(e_i) \label{enc:cf:seq} \\
\phi_{CF_{br}}  \defeq \quad & [\fx(e_i) \Rightarrow \fx(e_k)] \ \land \ \cdots \ \land \ [\fx(e_{i+j}) \Rightarrow \fx(e_k)] \nonumber \\
                       \land & \ [\fx(e_i) \land \fx(e_k) \Rightarrow g_{i,k}] \ \land \ \cdots \ \land \ [\fx(e_{i+j}) \land \fx(e_k) \Rightarrow g_{i+j,k}] \nonumber \\
                       \land & \ \cdots \nonumber \\
                       \land & \ ( \bigvee_{e_l \in \ \texttt{succ}(e_m)} \ \
                               \bigvee_{\begin{subarray}{l}e_n \in \ \texttt{succ}(e_k) \\ e_n \neq e_m\end{subarray}} 
                              \! \lnot [\fx(e_m) \land \fx(e_n)] \ ) \label{enc:cf:br} \\
\phi_{CF_{mer}} \defeq \quad & \fx(e_k) \Rightarrow (\bigvee\limits_{e_p \in \ \texttt{pred}(e_k)}^{} \fx(e_p)) \label{enc:cf:merge}
\end{align}

Equation~\ref{enc:cf:seq} shows the encoding for the sequential control-flow represented in Figure~\ref{encode:cf:seq} and reflects the fact that the event $e_2$ can be executed iff the event $e_1$ has been executed.
Equation~\ref{enc:cf:br} shows the encoding for the branching control-flow depicted in Figure~\ref{encode:cf:br}, that considers both transitions and guards.
Also, adding negations of pairwise conjunctions over all successors of the branching node, the encoding forbids the execution of two branches simultaneously.
Equation~\ref{enc:cf:merge} shows the encoding for the control-flow of a merge-point represented in Figure~\ref{encode:cf:merge}: the event $e_k$ is executed if either of its predecessors has been executed, regardless the type of the transition.
Note that the sequential control-flow is a special case of branching with the only transition guard $\epsilon$ (that is encoded as \texttt{true}).

For sake of correctness and simplicity of the encoding, we require all branches to have at least one event.
Thus, for branching statements that do not have any events in one of the branches (such branch represents a conditional jump forward), we add a synthetic \textit{nop-event} as it is shown in Figure~\ref{encode:branching:nop}.

\begin{figure}[t]%[!h]
    \centering
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.5cm,semithick]
        \node[c] at (0,0) (1a) {$e_1$};
        \node[c] at (0,-1.5) (2a) {$e_2$};
        \node[c] at (0,-3) (3a) {$e_3$};
        \node[c,draw=none] at (3,-1.5) (arr) {$\longrightarrow$};
        \node[c] at (6,0) (1b) {$e_1$};
        \node[c] at (6,-1.5) (2b) {$e_2$};
        \node[c,fill=black!15] at (7.5,-1.5) (nop) {$e_{nop}$};
        \node[c] at (6,-3) (3b) {$e_3$};
        \path[->]
        (1a) edge [] node {} (2a)
        (2a) edge [] node {} (3a)
        (1a) edge [dotted,bend left=60] node {} (3a)
        (1b) edge [] node {} (2b)
        (2b) edge [] node {} (3b)
        (1b) edge [dotted,bend left] node {} (nop)
        (nop) edge [dotted,bend left] node {} (3b)
        ;
    \end{tikzpicture}
    \caption{Transformation of the forward-jump control-flow}
    \label{encode:branching:nop}
\end{figure}

\begin{figure}[t]
\begin{minipage}{.4\textwidth}
\centering
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.5cm,semithick]
    \node[c] (i)   [] {$e_1$};
    \node[c] (ii)  [below of=i] {$e_2$};
    \node[c,fill=black!15] (lnop) [below left = 0.25cm and 0.7cm of ii] {$e_{nop_{1}}$};
    \node[c] (iii) [below of=ii] {$e_3$};
    \node[c,fill=black!15] (rnop) [right = 0.4cm of iii] {$e_{nop_{2}}$};
    \node[c] (iv)  [below of=iii] {$e_4$};
    \path[->]
    (i) edge [right] node {$\epsilon$} (ii)
    (i) edge [right,bend right=25] node {$g_{1,4}$} (lnop)
    (lnop) edge [right,bend right=25] node {$\epsilon$} (iv)
    (ii) edge [right] node {$g_{2,3}$} (iii)
    (iii) edge [right] node {$\epsilon$} (iv)
    (ii) edge [right,bend left=25] node {$g_{2,4}$} (rnop)
    (rnop) edge [right,bend left=25] node {$\epsilon$} (iv)
    ;
\end{tikzpicture}
\end{minipage}
%
\begin{minipage}{.6\textwidth}
\centering
\begin{align*}
\phi_{CF} \defeq \ & [\fx(e_2) \Rightarrow \fx(e_1)] \\
                 \ & \land [\fx(e_3) \Rightarrow \fx(e_2)] \\
                 \ & \land [\fx(e_{nop_{1}}) \Rightarrow \fx(e_1)] \\
                 \ & \land [\fx(e_{nop_{2}}) \Rightarrow \fx(e_2)] \\
                 \ & \land [\fx(e_4) \Rightarrow (\fx(e_{nop_{1}}) \lor \fx(e_3) \lor \fx(e_{nop_{2}}))] \\
                 \ & \land [\fx(e_{nop_{1}}) \land \fx(e_1) \Rightarrow g_{1,4}] \\
                 \ & \land [(\fx(e_3) \land \fx(e_2)) \Rightarrow g_{2,3}] \\
                 \ & \land [(\fx(e_{nop_{2}}) \land \fx(e_2)) \Rightarrow g_{2,4}] \\
                 \ & \land \lnot [\fx(e_2) \land \fx(e_{nop_{1}})] \\
                 \ & \land \lnot [\fx(e_3) \land \fx(e_{nop_{2}})]
\end{align*}
\end{minipage}
\caption{Example of encoding for the control-flow of the \xgraph{}}
\label{fig:graph-example}
\end{figure}

%this paragraph should go after the Figure{fig:graph-example} so that the fig is on the top of the same page 
As an example of the control-flow encoding, consider the event-flow graph in Figure~\ref{fig:graph-example}, which has two branching points and one merge point with three incoming transitions.
To illustrate the correctness of the encoding, consider the path $e_1 \rightarrow e_2 \rightarrow e_4$.
This means, in the formula $\phi_{CF}$, the SMT-variables $\fx(e_1)$, $\fx(e_2)$ and $\fx(e_4)$ should be assigned to  $1$, and the variable $\fx(e_3)$ should be assigned to $0$.
%It is easy to check that the $\phi_{CF}$ is satisfiable by the chosen SMT-model (considering the guards $g_{1,2}$ and $g_{2,4}$ that define this path to be evaluated to $1$).

Note that the generalised encoding scheme does not require the branching transitions to be mutually-exclusive (for instance, consider two branching transitions from the event $e_2$, both labelled by non-epsilon guards $g_{2,3}$ and $g_{2,4}$).
Next, consider the path $e_1 \rightarrow e_3 \rightarrow e_4$, which is not allowed by the control-flow graph.
The corresponding model $\fx(e_1)=1$, $\fx(e_2)=0$, $\fx(e_3)=1$ and $\fx(e_4)=1$ does not satisfy the formula $\phi_{CF}$.
The proposed encoding for the control-flow works also for encoding the partial graph.
For example, the assignment $\fx(e_1)=1$, $\fx(e_2)=1$, $\fx(e_3)=0$ and $\fx(e_4)=0$, which encodes the path $e_1 \rightarrow e_2$, satisfies $\phi_{CF}$.

\subsection{Encoding for the data-flow}
\label{ch:enc:bmc:df}

To encode the data-flow constraints, we use the \textit{Static Single-Assignment~(SSA) form} in order to be able to capture an arbitrary data-flow into a single SMT-formula.
The SSA form requires each variable to be assigned only once within entire program.
In contrast, \porthos{} used the \textit{Dynamic Single-Assignment~(DSA)} form, that requires indices to be unique only within a control-flow branch.
Although the number of variable references (each of which is encoded as unique SMT-variable) on average is logarithmically less in the case of the DSA form than the SSA form, the result SMT-formula still needs to be complemented by same number of equality assertions when encoding the data-flow of merge points~\cite{Porthos17a}.

Following~\cite{Porthos17b}, the indexed references of variables are computed in accordance with the following rules:
(1)~any access to a shared variable (both read and write) increments its SSA-index;
(2)~only writes to a local variable increment its SSA-index (reads preserve indices);
(3)~no access to a constant variable or computed (evaluated) expression changes their SSA-index.
These rules determine the following encoding of load, store and computation events within a single thread:
%
\begin{align}
    \phi_{DF_{e = \texttt{load}(r \leftarrow l)}}  \defeq \ & [\fx(e) \Rightarrow (r_{i+1} = l_{i+1})] \label{enc:df:load} \\
    \phi_{DF_{e = \texttt{store}(l \leftarrow r)}} \defeq \ & [\fx(e) \Rightarrow (l_{i+1} = r_i)] \label{enc:df:store} \\
    \phi_{DF_{e = \texttt{eval}(\cdot)}}           \defeq \ & [\fx(e) \Rightarrow \fv(e)] \label{enc:df:eval} % \\
\end{align}

In Equation~\ref{enc:df:eval}, the function $\fv:\,\mathbb{C}\,\rightarrow\,\mathbb{R}$ e\textbf{v}aluates the computation event (the value is determined by \co- and \rf- relations).
To convert the program into SSA form, for each event each variable that is declared so far (either local or shared) is mapped to its indexed reference; this information is stored in the SSA-map "event \textit{to} variable \textit{to} SSA-index". %for each event stores the map that each declared variable maps to its SSA-index
%"$\{$ event : $\{$ variable : index $\}\}$",
%"$\left\{$ event : $\left\{$ variable : index $\right\} \right\}$",
The SSA-map is computed iteratively while traversing the event-flow graph in topological order as it is described in Algorithm~\ref{algorithm:ssa-map}.

\begin{algorithm}
    \caption{Algorithm for computing the SSA-indices}\label{alg:compute-ssa}
    \algorithmicrequire{The event-flow graph $G = \langle N, E \rangle$ where $V$ is the set of nodes (events), $E$ is the set of control-flow transitions, $e_0$ is the entry node}
    \algorithmicensure{The SSA-map of the form "$\{$ event : $\{$ variable : index $\}\}$"}
    \begin{algorithmic}[1]
        \Function{Compute-SSA-Map}{G}
            \State {$S \gets$ empty map; $S[e_0] \gets$ empty map}
            \ForAll {event $e_i \in G.N$ in topological order}
                \ForAll {predecessor $e_j \in \texttt{pred}(e_i)$}
                    \State {$S[e_i] \gets \texttt{copy}(S[e_j])$}
                    \ForAll {variable $v_k \in$ set of variables accessed by $e_i$ }
                        \State {$S[e_i][v_k] \gets \texttt{max}(S[e_i][v_k], \ S[e_j][v_k])$}
                        \If {need to update the index of $v_k$} \Comment {cases (1)-(2)}
                            \State {$S[e_i][v_k] \gets S[e_i][v_k] + 1$}
                        \EndIf
                    \EndFor
                \EndFor
            \EndFor
        \EndFunction
    \end{algorithmic}
    \label{algorithm:ssa-map}
\end{algorithm}

The time of described algorithm is linear of the event-flow graph size as the algorithm performs only a single graph traverse.

As it has been described before, the \rf-relation links data-flow between events.
%of data-flow stored in equivalence assertions over the SSA-variables. 
%The encoding of the \rf-relation, which links the SSA-variables to the original variables, 
The encoding of this linkage has been left untouched as it is implemented in \porthos[1]: %for each pair of events $e_1$ and $e_2$ linked by the \rf-relation, we add the following constraint:
%
\begin{align}
\phi_{DF_{mem}}(e_1, e_2) \defeq \ & [\texttt{rf}(e_1, e_2) \Rightarrow (l_i = l_j)]
\end{align}

where the variable of location $l$ is mapped to the SSA-variable $l_i$ for event $e_1$, and to the SSA-variable $l_j$ for event $e_2$; and the predicate $\texttt{rf}(e_1, e_2)$ is encoded as a boolean variable, which itself equals $\textit{true}$ if $e_1 \relarrow{rf} e_2$ (i.e., if $e_2$ reads the shared variable that was written in $e_1$).


\subsection{Encoding for the memory model}
\label{ch:enc:bmc:wmm}

The basic scheme for encoding the memory model was proposed in~\cite{Porthos17a}.
The encoding consists of two parts: encoding of the \textit{derived relations} and encoding of the memory model \textit{assertions}.

In the SMT-formula, a relation $x \relarrow{r} y$ is represented by a boolean variable $r(x, y)$ that indicates whether the relation holds.
Derived relations are encoded by fresh boolean variables according to the following rules~\cite{Porthos17b}:
\begin{itemize}[noitemsep,topsep=0pt]
\item $r_1 \cup r_2(e_1, e_2) \defeq r_1(e_1, e_2) \lor r_2(e_1, e_2)$;
\item $r_1 \cap r_2(e_1, e_2) \defeq r_1(e_1, e_2) \land r_2(e_1, e_2)$;
\item $r_1 \relminus r_2(e_1, e_2) \defeq r_1(e_1, e_2) \land \neg r_2(e_1, e_2)$;
\item $r^{-1}(e_1, e_2) \defeq r(e_2, e_1)$;
\item $r^{*}(e_1, e_2) \defeq r^{+}(e_1, e_2) \lor (e_1 = e_2)$;
\item $r_1;r_2(e_1,e_2) \defeq \bigvee\limits_{e_k \in \mathbb{E}}^{} r_1(e_1,e_k) \land r_2(e_k,e_2)$; \ and
\item $r^{+}(e_1, e_2) \defeq \texttt{tc}_{\left\lceil log|\mathbb{E}| \right\rceil} (e_1, e_2), \ where \vspace{0.25em} \\
\texttt{tc}_{0}(e_1,e_2) \defeq r(e_1,e_2), \ and \\
\texttt{tc}_{i+1}(e_1,e_2) \defeq r(e_1,e_2) \lor (\texttt{tc}_{i}(e_1,e_3);\texttt{tc}_{i}(e_3,e_2))$.
\end{itemize}
\vspace{1em}

Note that \cat{} language allows mutually-recursive definitions of relations (for example, `$\texttt{r}_\texttt{1} = \texttt{r}_\texttt{2} \cup (\texttt{r}_\texttt{1}; \texttt{r}_\texttt{1})$').
The basic idea of using the Kleene fixpoint iteration for encoding such relations was also proposed in~\cite{Porthos17a}: for any pair of events $e_1,e_2 \in \mathbb{E}$ and relation $r \subseteq \mathbb{E} \times \mathbb{E}$, we encode a new integer variable $\Phi_{e_1,e_2}^{r}$ that represents the round of Kleene iteration on which the variable $r(e_1, e_2)$ has been set.
 %is used for guessing the execution 

The memory model can assert acyclicity, irreflexivity of emptiness of a relation or a set of events.
As it has been proposed in~\cite{Porthos17a}, encoding the acyclicity assertion uses numerical variable $\Psi_e \in \mathbb{N}$ for each event $e$ in the relation to be asserted: $\textit{acyclic}(r) \defeq (r(e_1,e_2) \Rightarrow (\Psi_{e_1} < \Psi_{e_2}))$.
The irreflexivity assertion as $\textit{irreflexive}(r) \defeq \bigwedge\limits_{e_k \in \mathbb(E)}^{} \lnot r(e_k,e_k)$.

%The ... \wmodel{}

%Most bounded model-checking problems are solved via computing the fixpoint for the

%The encoding of a weak memory model itself does not depend on the analysing program. The problem here...
%recursive definitions and Kleene iteration

%r 1 ∪r 2 (e 1 , e 2 ) ⇔ r 1 (e 1 , e 2 ) ∨ r 2 (e 1 , e 2 )
%r 1 ∩r 2 (e 1 , e 2 ) ⇔ r 1 (e 1 , e 2 ) ∧ r 2 (e 1 , e 2 )
%r 1 \r 2 (e 1 , e 2 ) ⇔ r W
%r −1 (e 1 , e 2 ) ⇔ r(e 2 , e 1 )
%1 (e 1 , e 2 ) ∧ ¬r 2 (e 1 , e 2 )
%r 1 (e 1 , e 3 ) ∧ r 2 (e 3 , e 2 )
%r ∗ (e 1 , e 2 ) ⇔ r + (e 1 , e 2 ) ∨ (e 1 = e 2 )
%r 1 ;r 2 (e 1 , e 2 ) ⇔
%e 3 ∈E
%r + (e 1 , e 2 ) ⇔ tc ⌈log |E|⌉ (e 1 , e 2 ), where
%tc 0 (e 1 , e 2 ) ⇔ r(e 1 , e 2 ), and
%tc i+1 (e 1 , e 2 ) ⇔ r(e 1 , e 2 ) ∨ (tc i (e 1 , e 2 ); tc i (e 1 , e 2 ))
%
%As it is described in~\cite{Porthos17a}, the is based . . .
%~\cite{Porthos17a}%, Section "Programs and Memory Models", subsection "Encoding Derived Relations"
